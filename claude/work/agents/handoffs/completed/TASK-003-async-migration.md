# TASK-003: éåŒæœŸå‡¦ç†ã¸ã®ç§»è¡Œ

## å‰²ã‚Šå½“ã¦: backend

## ç›®çš„
ç¾åœ¨ã®åŒæœŸçš„ãªå‡¦ç†ã‚’éåŒæœŸå‡¦ç†ã«ç§»è¡Œã—ã€ä¸¦è¡Œå‡¦ç†ã‚’æ´»ç”¨ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚

## èƒŒæ™¯
ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å•é¡Œç‚¹ï¼š
- `requests`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸåŒæœŸçš„ãªHTTPé€šä¿¡
- è¤‡æ•°ã®APIã‚’é †æ¬¡å‘¼ã³å‡ºã—ã¦ã„ã‚‹
- I/Oå¾…æ©Ÿæ™‚é–“ãŒç„¡é§„ã«ãªã£ã¦ã„ã‚‹
- `run_services.py`ãŒå„ã‚µãƒ¼ãƒ“ã‚¹ã‚’é †ç•ªã«å®Ÿè¡Œ

## å®Ÿè£…å†…å®¹

### 1. éåŒæœŸHTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
**ãƒ•ã‚¡ã‚¤ãƒ«**: `nook/common/http_client.py`

```python
import httpx
import asyncio
from typing import Optional, Dict, Any, Union
from datetime import datetime
import logging
from contextlib import asynccontextmanager

from nook.common.exceptions import APIException, RetryException
from nook.common.decorators import handle_errors
from nook.common.config import BaseConfig


logger = logging.getLogger(__name__)


class AsyncHTTPClient:
    """éåŒæœŸHTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ with connection pooling"""
    
    def __init__(self, config: BaseConfig = None):
        self.config = config or BaseConfig()
        self.timeout = httpx.Timeout(
            timeout=self.config.REQUEST_TIMEOUT,
            connect=5.0,
            read=self.config.REQUEST_TIMEOUT,
            write=5.0,
            pool=5.0
        )
        self.limits = httpx.Limits(
            max_keepalive_connections=20,
            max_connections=100,
            keepalive_expiry=30.0
        )
        self._client: Optional[httpx.AsyncClient] = None
        self._session_start: Optional[datetime] = None
    
    async def __aenter__(self):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼"""
        await self.start()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¨ã‚°ã‚¸ãƒƒãƒˆ"""
        await self.close()
    
    async def start(self):
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹"""
        if self._client is None:
            self._client = httpx.AsyncClient(
                timeout=self.timeout,
                limits=self.limits,
                follow_redirects=True,
                http2=True  # HTTP/2ã‚µãƒãƒ¼ãƒˆ
            )
            self._session_start = datetime.utcnow()
            logger.info("HTTP client session started")
    
    async def close(self):
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†"""
        if self._client:
            await self._client.aclose()
            self._client = None
            
            if self._session_start:
                duration = (datetime.utcnow() - self._session_start).total_seconds()
                logger.info(f"HTTP client session closed after {duration:.2f} seconds")
    
    @handle_errors(retries=3, delay=1.0, backoff=2.0)
    async def get(
        self,
        url: str,
        headers: Optional[Dict[str, str]] = None,
        params: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> httpx.Response:
        """GET ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        if not self._client:
            await self.start()
        
        logger.debug(f"GET {url}", extra={"params": params})
        
        try:
            response = await self._client.get(
                url,
                headers=headers,
                params=params,
                **kwargs
            )
            response.raise_for_status()
            
            logger.debug(
                f"GET {url} completed",
                extra={
                    "status_code": response.status_code,
                    "response_time": response.elapsed.total_seconds()
                }
            )
            
            return response
            
        except httpx.HTTPStatusError as e:
            logger.error(f"HTTP error for {url}: {e}")
            raise APIException(
                f"HTTP {e.response.status_code} error",
                status_code=e.response.status_code,
                response_body=e.response.text
            ) from e
        
        except httpx.RequestError as e:
            logger.error(f"Request error for {url}: {e}")
            raise APIException(f"Request failed: {str(e)}") from e
    
    @handle_errors(retries=3, delay=1.0, backoff=2.0)
    async def post(
        self,
        url: str,
        json: Optional[Dict[str, Any]] = None,
        data: Optional[Union[Dict[str, Any], bytes]] = None,
        headers: Optional[Dict[str, str]] = None,
        **kwargs
    ) -> httpx.Response:
        """POST ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        if not self._client:
            await self.start()
        
        logger.debug(f"POST {url}")
        
        try:
            response = await self._client.post(
                url,
                json=json,
                data=data,
                headers=headers,
                **kwargs
            )
            response.raise_for_status()
            
            logger.debug(
                f"POST {url} completed",
                extra={"status_code": response.status_code}
            )
            
            return response
            
        except httpx.HTTPStatusError as e:
            logger.error(f"HTTP error for {url}: {e}")
            raise APIException(
                f"HTTP {e.response.status_code} error",
                status_code=e.response.status_code,
                response_body=e.response.text
            ) from e
        
        except httpx.RequestError as e:
            logger.error(f"Request error for {url}: {e}")
            raise APIException(f"Request failed: {str(e)}") from e
    
    async def get_json(self, url: str, **kwargs) -> Dict[str, Any]:
        """JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—"""
        response = await self.get(url, **kwargs)
        return response.json()
    
    async def get_text(self, url: str, **kwargs) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—"""
        response = await self.get(url, **kwargs)
        return response.text
    
    async def download(
        self,
        url: str,
        output_path: str,
        chunk_size: int = 8192,
        progress_callback=None
    ):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        if not self._client:
            await self.start()
        
        async with self._client.stream("GET", url) as response:
            response.raise_for_status()
            
            total_size = int(response.headers.get("content-length", 0))
            downloaded = 0
            
            with open(output_path, "wb") as f:
                async for chunk in response.aiter_bytes(chunk_size):
                    f.write(chunk)
                    downloaded += len(chunk)
                    
                    if progress_callback:
                        await progress_callback(downloaded, total_size)
            
            logger.info(f"Downloaded {url} to {output_path}")


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰
_global_client: Optional[AsyncHTTPClient] = None


async def get_http_client() -> AsyncHTTPClient:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—"""
    global _global_client
    
    if _global_client is None:
        _global_client = AsyncHTTPClient()
        await _global_client.start()
    
    return _global_client


async def close_http_client():
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é–‰ã˜ã‚‹"""
    global _global_client
    
    if _global_client:
        await _global_client.close()
        _global_client = None
```

### 2. ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãHTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
**ãƒ•ã‚¡ã‚¤ãƒ«**: `nook/common/rate_limiter.py`

```python
import asyncio
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging
from collections import defaultdict
from contextlib import asynccontextmanager


logger = logging.getLogger(__name__)


class RateLimiter:
    """APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ç®¡ç†"""
    
    def __init__(
        self,
        rate: int,
        per: timedelta = timedelta(seconds=1),
        burst: Optional[int] = None
    ):
        self.rate = rate
        self.per = per
        self.burst = burst or rate
        self.allowance = float(self.burst)
        self.last_check = datetime.utcnow()
        self._lock = asyncio.Lock()
    
    async def acquire(self, tokens: int = 1):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦å¿…è¦ã«å¿œã˜ã¦å¾…æ©Ÿ"""
        async with self._lock:
            now = datetime.utcnow()
            elapsed = (now - self.last_check).total_seconds()
            self.last_check = now
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å›å¾©
            self.allowance += elapsed * (self.rate / self.per.total_seconds())
            if self.allowance > self.burst:
                self.allowance = float(self.burst)
            
            if self.allowance < tokens:
                # å¿…è¦ãªãƒˆãƒ¼ã‚¯ãƒ³ãŒå›å¾©ã™ã‚‹ã¾ã§ã®æ™‚é–“ã‚’è¨ˆç®—
                deficit = tokens - self.allowance
                wait_time = deficit * (self.per.total_seconds() / self.rate)
                
                logger.debug(
                    f"Rate limit reached, waiting {wait_time:.2f} seconds",
                    extra={"tokens_needed": tokens, "allowance": self.allowance}
                )
                
                await asyncio.sleep(wait_time)
                
                # å¾…æ©Ÿå¾Œã«å†åº¦è¨ˆç®—
                now = datetime.utcnow()
                elapsed = (now - self.last_check).total_seconds()
                self.last_check = now
                self.allowance += elapsed * (self.rate / self.per.total_seconds())
                if self.allowance > self.burst:
                    self.allowance = float(self.burst)
            
            self.allowance -= tokens


class RateLimitedHTTPClient(AsyncHTTPClient):
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™æ©Ÿèƒ½ä»˜ãHTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(
        self,
        config: BaseConfig = None,
        default_rate_limit: Optional[RateLimiter] = None
    ):
        super().__init__(config)
        self.default_rate_limit = default_rate_limit or RateLimiter(
            rate=60,
            per=timedelta(minutes=1)
        )
        self.domain_rate_limits: Dict[str, RateLimiter] = {}
    
    def add_domain_rate_limit(
        self,
        domain: str,
        rate: int,
        per: timedelta = timedelta(seconds=1),
        burst: Optional[int] = None
    ):
        """ç‰¹å®šãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è¨­å®š"""
        self.domain_rate_limits[domain] = RateLimiter(rate, per, burst)
    
    def _get_domain(self, url: str) -> str:
        """URLã‹ã‚‰ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æŠ½å‡º"""
        from urllib.parse import urlparse
        return urlparse(url).netloc
    
    async def _acquire_rate_limit(self, url: str, tokens: int = 1):
        """URLã«å¯¾å¿œã™ã‚‹ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å–å¾—ã—ã¦å¾…æ©Ÿ"""
        domain = self._get_domain(url)
        
        if domain in self.domain_rate_limits:
            rate_limiter = self.domain_rate_limits[domain]
        else:
            rate_limiter = self.default_rate_limit
        
        await rate_limiter.acquire(tokens)
    
    async def get(self, url: str, **kwargs) -> httpx.Response:
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãGETãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        await self._acquire_rate_limit(url)
        return await super().get(url, **kwargs)
    
    async def post(self, url: str, **kwargs) -> httpx.Response:
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãPOSTãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        await self._acquire_rate_limit(url)
        return await super().post(url, **kwargs)
```

### 3. ä¸¦è¡Œå‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
**ãƒ•ã‚¡ã‚¤ãƒ«**: `nook/common/async_utils.py`

```python
import asyncio
from typing import List, Callable, Any, TypeVar, Optional, Dict, Tuple
from concurrent.futures import ThreadPoolExecutor
import logging
from datetime import datetime
from functools import partial


logger = logging.getLogger(__name__)
T = TypeVar('T')


class TaskResult:
    """ã‚¿ã‚¹ã‚¯å®Ÿè¡Œçµæœ"""
    
    def __init__(self, name: str, success: bool, result: Any = None, error: Exception = None):
        self.name = name
        self.success = success
        self.result = result
        self.error = error
        self.timestamp = datetime.utcnow()


async def gather_with_errors(
    *coros,
    return_exceptions: bool = True,
    task_names: Optional[List[str]] = None
) -> List[TaskResult]:
    """è¤‡æ•°ã®ã‚³ãƒ«ãƒ¼ãƒãƒ³ã‚’ä¸¦è¡Œå®Ÿè¡Œã—ã€ã‚¨ãƒ©ãƒ¼ã‚‚å«ã‚ã¦çµæœã‚’è¿”ã™"""
    if task_names and len(task_names) != len(coros):
        raise ValueError("task_names must have the same length as coros")
    
    if not task_names:
        task_names = [f"Task-{i}" for i in range(len(coros))]
    
    results = await asyncio.gather(*coros, return_exceptions=return_exceptions)
    
    task_results = []
    for i, (name, result) in enumerate(zip(task_names, results)):
        if isinstance(result, Exception):
            logger.error(f"Task {name} failed: {result}")
            task_results.append(TaskResult(name, False, error=result))
        else:
            task_results.append(TaskResult(name, True, result=result))
    
    return task_results


async def run_with_semaphore(
    coros: List[Callable[[], Any]],
    max_concurrent: int = 10,
    progress_callback: Optional[Callable[[int, int], None]] = None
) -> List[Any]:
    """ã‚»ãƒãƒ•ã‚©ã‚’ä½¿ã£ã¦ä¸¦è¡Œå®Ÿè¡Œæ•°ã‚’åˆ¶é™"""
    semaphore = asyncio.Semaphore(max_concurrent)
    total = len(coros)
    completed = 0
    
    async def run_with_limit(coro_func):
        async with semaphore:
            result = await coro_func()
            
            nonlocal completed
            completed += 1
            
            if progress_callback:
                await progress_callback(completed, total)
            
            return result
    
    tasks = [run_with_limit(coro) for coro in coros]
    return await asyncio.gather(*tasks)


async def batch_process(
    items: List[T],
    processor: Callable[[List[T]], Any],
    batch_size: int = 100,
    max_concurrent_batches: int = 5
) -> List[Any]:
    """ã‚¢ã‚¤ãƒ†ãƒ ã‚’ãƒãƒƒãƒå‡¦ç†"""
    batches = [items[i:i + batch_size] for i in range(0, len(items), batch_size)]
    
    async def process_batch(batch):
        return await processor(batch)
    
    return await run_with_semaphore(
        [partial(process_batch, batch) for batch in batches],
        max_concurrent=max_concurrent_batches
    )


def run_sync_in_thread(
    sync_func: Callable[..., T],
    *args,
    **kwargs
) -> asyncio.Future[T]:
    """åŒæœŸé–¢æ•°ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ"""
    loop = asyncio.get_event_loop()
    executor = ThreadPoolExecutor(max_workers=1)
    
    return loop.run_in_executor(
        executor,
        partial(sync_func, *args, **kwargs)
    )


class AsyncTaskManager:
    """éåŒæœŸã‚¿ã‚¹ã‚¯ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
    
    def __init__(self, max_concurrent: int = 10):
        self.max_concurrent = max_concurrent
        self.tasks: Dict[str, asyncio.Task] = {}
        self.results: Dict[str, Any] = {}
        self.errors: Dict[str, Exception] = {}
        self._lock = asyncio.Lock()
    
    async def submit(self, name: str, coro) -> str:
        """ã‚¿ã‚¹ã‚¯ã‚’é€ä¿¡"""
        async with self._lock:
            if name in self.tasks:
                raise ValueError(f"Task {name} already exists")
            
            task = asyncio.create_task(self._run_task(name, coro))
            self.tasks[name] = task
            
            return name
    
    async def _run_task(self, name: str, coro):
        """ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ"""
        try:
            result = await coro
            async with self._lock:
                self.results[name] = result
                logger.info(f"Task {name} completed successfully")
        except Exception as e:
            async with self._lock:
                self.errors[name] = e
                logger.error(f"Task {name} failed: {e}")
        finally:
            async with self._lock:
                if name in self.tasks:
                    del self.tasks[name]
    
    async def wait_for(self, name: str, timeout: Optional[float] = None) -> Any:
        """ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å¾…ã¤"""
        task = self.tasks.get(name)
        if not task:
            if name in self.results:
                return self.results[name]
            elif name in self.errors:
                raise self.errors[name]
            else:
                raise ValueError(f"Task {name} not found")
        
        try:
            await asyncio.wait_for(task, timeout=timeout)
        except asyncio.TimeoutError:
            logger.error(f"Task {name} timed out")
            raise
        
        if name in self.errors:
            raise self.errors[name]
        
        return self.results.get(name)
    
    async def wait_all(self, timeout: Optional[float] = None) -> Dict[str, Any]:
        """ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å¾…ã¤"""
        if self.tasks:
            tasks = list(self.tasks.values())
            await asyncio.wait(tasks, timeout=timeout)
        
        return {
            "results": self.results.copy(),
            "errors": self.errors.copy()
        }
    
    def get_status(self) -> Dict[str, Any]:
        """ã‚¿ã‚¹ã‚¯ã®çŠ¶æ…‹ã‚’å–å¾—"""
        return {
            "running": list(self.tasks.keys()),
            "completed": list(self.results.keys()),
            "failed": list(self.errors.keys()),
            "total": len(self.tasks) + len(self.results) + len(self.errors)
        }
```

### 4. ã‚µãƒ¼ãƒ“ã‚¹ã®éåŒæœŸåŒ–ï¼ˆä¾‹: GitHubã‚µãƒ¼ãƒ“ã‚¹ï¼‰
**ãƒ•ã‚¡ã‚¤ãƒ«**: `nook/services/github_trending.py` (ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œ)

```python
import asyncio
from datetime import datetime
from typing import List, Dict, Any
import toml

from nook.common.base_service import BaseService
from nook.common.http_client import get_http_client
from nook.common.async_utils import gather_with_errors, run_with_semaphore
from nook.common.decorators import handle_errors, log_execution_time
from nook.common.service_errors import ServiceErrorHandler


class GitHubTrendingService(BaseService):
    """GitHub Trending ãƒªãƒã‚¸ãƒˆãƒªã®åé›†ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        super().__init__("github_trending")
        self.error_handler = ServiceErrorHandler(self.service_name)
        self.languages = self._load_languages()
    
    def _load_languages(self) -> List[str]:
        """è¨€èªè¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open("nook/services/github_trending/languages.toml", "r") as f:
                config = toml.load(f)
                return config.get("languages", [])
        except Exception as e:
            self.logger.error(f"Failed to load languages: {e}")
            return ["python", "javascript", "go"]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    @log_execution_time
    async def collect(self) -> None:
        """ãƒ¡ã‚¤ãƒ³ã®åé›†å‡¦ç†"""
        self.logger.info("Starting GitHub trending collection")
        
        async with await get_http_client() as client:
            # å„è¨€èªã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ä¸¦è¡Œå–å¾—
            language_tasks = [
                self._collect_language_trending(client, language)
                for language in self.languages
            ]
            
            results = await gather_with_errors(
                *language_tasks,
                task_names=self.languages
            )
            
            # çµæœã‚’ãƒãƒ¼ã‚¸
            all_repos = []
            for result in results:
                if result.success and result.result:
                    all_repos.extend(result.result)
            
            if all_repos:
                # ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’ä¸¦è¡Œå–å¾—
                enriched_repos = await self._enrich_repositories(client, all_repos)
                
                # Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
                report = await self._generate_report(enriched_repos)
                
                # ä¿å­˜
                filename = f"github_trending_{datetime.now().strftime('%Y-%m-%d')}.md"
                await self.save_markdown(report, filename)
                
                self.logger.info(f"Collected {len(enriched_repos)} repositories")
            else:
                self.logger.warning("No repositories collected")
    
    @handle_errors(retries=3)
    @ServiceErrorHandler.handle_api_error("GitHub")
    async def _collect_language_trending(
        self,
        client,
        language: str
    ) -> List[Dict[str, Any]]:
        """ç‰¹å®šè¨€èªã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—"""
        url = f"https://api.github.com/search/repositories"
        params = {
            "q": f"language:{language} stars:>100",
            "sort": "stars",
            "order": "desc",
            "per_page": 10
        }
        
        response = await client.get(url, params=params)
        data = response.json()
        
        return data.get("items", [])
    
    async def _enrich_repositories(
        self,
        client,
        repos: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ãƒªãƒã‚¸ãƒˆãƒªã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        async def get_repo_details(repo):
            try:
                # READMEã‚’å–å¾—
                readme_url = f"{repo['url']}/readme"
                readme_response = await client.get(
                    readme_url,
                    headers={"Accept": "application/vnd.github.v3.raw"}
                )
                
                # GPTã§è¦ç´„
                if readme_response.status_code == 200:
                    summary = await self._summarize_readme(readme_response.text)
                    repo["summary"] = summary
                else:
                    repo["summary"] = repo.get("description", "No description")
                
                return repo
            except Exception as e:
                self.logger.warning(f"Failed to enrich repo {repo['name']}: {e}")
                repo["summary"] = repo.get("description", "No description")
                return repo
        
        # ã‚»ãƒãƒ•ã‚©ã§ä¸¦è¡Œæ•°ã‚’åˆ¶é™ï¼ˆGitHub API ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰
        enriched = await run_with_semaphore(
            [lambda r=repo: get_repo_details(r) for repo in repos],
            max_concurrent=5
        )
        
        return enriched
    
    async def _summarize_readme(self, readme_text: str) -> str:
        """READMEã‚’è¦ç´„ï¼ˆéåŒæœŸï¼‰"""
        # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
        if len(readme_text) > 5000:
            readme_text = readme_text[:5000] + "..."
        
        prompt = f"""
        ä»¥ä¸‹ã®READMEã‚’æ—¥æœ¬èªã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ï¼ˆ100æ–‡å­—ä»¥å†…ï¼‰:
        
        {readme_text}
        """
        
        # GPTã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®éåŒæœŸå¯¾å¿œï¼ˆä»®å®Ÿè£…ï¼‰
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€GPTã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚‚éåŒæœŸåŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        summary = await asyncio.get_event_loop().run_in_executor(
            None,
            self.gpt_client.generate,
            prompt
        )
        
        return summary
    
    async def _generate_report(self, repos: List[Dict[str, Any]]) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        lines = [
            f"# GitHub Trending - {datetime.now().strftime('%Y-%m-%d')}",
            "",
            "æœ¬æ—¥ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªãƒã‚¸ãƒˆãƒª",
            ""
        ]
        
        # è¨€èªåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        by_language = {}
        for repo in repos:
            lang = repo.get("language", "Unknown")
            if lang not in by_language:
                by_language[lang] = []
            by_language[lang].append(repo)
        
        for language, lang_repos in sorted(by_language.items()):
            lines.append(f"## {language}")
            lines.append("")
            
            for repo in sorted(lang_repos, key=lambda x: x.get("stargazers_count", 0), reverse=True):
                lines.extend([
                    f"### [{repo['name']}]({repo['html_url']})",
                    f"â­ {repo.get('stargazers_count', 0):,} stars | "
                    f"ğŸ´ {repo.get('forks_count', 0):,} forks",
                    "",
                    repo.get("summary", "No description"),
                    ""
                ])
        
        return "\n".join(lines)
```

### 5. ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆã®éåŒæœŸåŒ–
**ãƒ•ã‚¡ã‚¤ãƒ«**: `nook/services/run_services.py` (ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œ)

```python
import asyncio
import logging
from typing import List, Optional
from datetime import datetime
import signal
import sys

from nook.services.github_trending import GitHubTrendingService
from nook.services.hacker_news import HackerNewsService
from nook.services.reddit_explorer import RedditExplorerService
from nook.services.tech_feed import TechFeedService
from nook.services.business_feed import BusinessFeedService

from nook.common.async_utils import AsyncTaskManager, gather_with_errors
from nook.common.logging import setup_logger
from nook.common.http_client import close_http_client


logger = setup_logger("service_runner")


class ServiceRunner:
    """ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè¡Œãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
    
    def __init__(self):
        self.services = [
            GitHubTrendingService(),
            HackerNewsService(),
            RedditExplorerService(),
            TechFeedService(),
            BusinessFeedService(),
        ]
        self.task_manager = AsyncTaskManager(max_concurrent=5)
        self.running = False
    
    async def run_all(self) -> None:
        """ã™ã¹ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä¸¦è¡Œå®Ÿè¡Œ"""
        self.running = True
        start_time = datetime.now()
        
        logger.info(f"Starting {len(self.services)} services")
        
        try:
            # å„ã‚µãƒ¼ãƒ“ã‚¹ã®collectãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä¸¦è¡Œå®Ÿè¡Œ
            service_tasks = [
                service.collect() for service in self.services
            ]
            
            results = await gather_with_errors(
                *service_tasks,
                task_names=[s.service_name for s in self.services]
            )
            
            # çµæœã‚’ãƒ¬ãƒãƒ¼ãƒˆ
            successful = sum(1 for r in results if r.success)
            failed = sum(1 for r in results if not r.success)
            
            duration = (datetime.now() - start_time).total_seconds()
            
            logger.info(
                f"Service run completed in {duration:.2f} seconds",
                extra={
                    "successful": successful,
                    "failed": failed,
                    "total": len(self.services)
                }
            )
            
            # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒ­ã‚°
            for result in results:
                if not result.success:
                    logger.error(
                        f"Service {result.name} failed",
                        extra={"error": str(result.error)}
                    )
            
        except Exception as e:
            logger.error(f"Service runner failed: {e}", exc_info=True)
            raise
        finally:
            self.running = False
            # HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            await close_http_client()
    
    async def run_service(self, service_name: str) -> None:
        """ç‰¹å®šã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’å®Ÿè¡Œ"""
        service = next(
            (s for s in self.services if s.service_name == service_name),
            None
        )
        
        if not service:
            raise ValueError(f"Service {service_name} not found")
        
        logger.info(f"Running service: {service_name}")
        
        try:
            await service.collect()
            logger.info(f"Service {service_name} completed successfully")
        except Exception as e:
            logger.error(f"Service {service_name} failed: {e}", exc_info=True)
            raise
    
    async def run_continuous(self, interval_seconds: int = 3600) -> None:
        """å®šæœŸçš„ã«ã‚µãƒ¼ãƒ“ã‚¹ã‚’å®Ÿè¡Œ"""
        logger.info(f"Starting continuous run with interval: {interval_seconds}s")
        
        while self.running:
            try:
                await self.run_all()
            except Exception as e:
                logger.error(f"Run failed: {e}", exc_info=True)
            
            # æ¬¡ã®å®Ÿè¡Œã¾ã§å¾…æ©Ÿ
            logger.info(f"Waiting {interval_seconds} seconds until next run")
            await asyncio.sleep(interval_seconds)
    
    def stop(self):
        """å®Ÿè¡Œã‚’åœæ­¢"""
        logger.info("Stopping service runner")
        self.running = False


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    runner = ServiceRunner()
    
    # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
    def signal_handler(sig, frame):
        logger.info(f"Received signal {sig}, shutting down...")
        runner.stop()
        sys.exit(0)
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    if len(sys.argv) > 1:
        if sys.argv[1] == "--continuous":
            interval = int(sys.argv[2]) if len(sys.argv) > 2 else 3600
            await runner.run_continuous(interval)
        else:
            # ç‰¹å®šã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’å®Ÿè¡Œ
            await runner.run_service(sys.argv[1])
    else:
        # ã™ã¹ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä¸€åº¦å®Ÿè¡Œ
        await runner.run_all()


if __name__ == "__main__":
    asyncio.run(main())
```

## ãƒ†ã‚¹ãƒˆè¦ä»¶

### ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
**ãƒ•ã‚¡ã‚¤ãƒ«**: `tests/common/test_async_http.py`

```python
import pytest
import httpx
from unittest.mock import AsyncMock, patch

from nook.common.http_client import AsyncHTTPClient, get_http_client
from nook.common.exceptions import APIException


@pytest.mark.asyncio
class TestAsyncHTTPClient:
    async def test_get_success(self):
        """GETãƒªã‚¯ã‚¨ã‚¹ãƒˆã®æˆåŠŸãƒ†ã‚¹ãƒˆ"""
        async with AsyncHTTPClient() as client:
            with patch.object(client._client, 'get') as mock_get:
                mock_response = AsyncMock()
                mock_response.status_code = 200
                mock_response.json.return_value = {"success": True}
                mock_response.raise_for_status = AsyncMock()
                mock_get.return_value = mock_response
                
                result = await client.get_json("https://example.com")
                
                assert result == {"success": True}
                mock_get.assert_called_once()
    
    async def test_get_retry_on_error(self):
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒªãƒˆãƒ©ã‚¤ãƒ†ã‚¹ãƒˆ"""
        async with AsyncHTTPClient() as client:
            with patch.object(client._client, 'get') as mock_get:
                # 2å›å¤±æ•—ã—ã¦3å›ç›®ã§æˆåŠŸ
                mock_get.side_effect = [
                    httpx.RequestError("Connection failed"),
                    httpx.RequestError("Connection failed"),
                    AsyncMock(
                        status_code=200,
                        json=AsyncMock(return_value={"success": True}),
                        raise_for_status=AsyncMock()
                    )
                ]
                
                result = await client.get_json("https://example.com")
                
                assert result == {"success": True}
                assert mock_get.call_count == 3
    
    async def test_rate_limiter(self):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãƒ†ã‚¹ãƒˆ"""
        from nook.common.rate_limiter import RateLimitedHTTPClient, RateLimiter
        from datetime import timedelta
        
        # 1ç§’ã«1ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®åˆ¶é™
        rate_limiter = RateLimiter(rate=1, per=timedelta(seconds=1))
        
        async with RateLimitedHTTPClient(default_rate_limit=rate_limiter) as client:
            with patch.object(client._client, 'get') as mock_get:
                mock_response = AsyncMock(
                    status_code=200,
                    raise_for_status=AsyncMock()
                )
                mock_get.return_value = mock_response
                
                import time
                start = time.time()
                
                # 2ã¤ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
                await client.get("https://example.com")
                await client.get("https://example.com")
                
                elapsed = time.time() - start
                
                # 2ç•ªç›®ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ç´„1ç§’å¾…æ©Ÿã™ã‚‹ã¯ãš
                assert elapsed >= 0.9  # å¤šå°‘ã®èª¤å·®ã‚’è¨±å®¹
```

### çµ±åˆãƒ†ã‚¹ãƒˆ
**ãƒ•ã‚¡ã‚¤ãƒ«**: `tests/integration/test_async_services.py`

```python
import pytest
import asyncio
from unittest.mock import patch, AsyncMock

from nook.services.run_services import ServiceRunner


@pytest.mark.asyncio
class TestServiceRunner:
    async def test_run_all_services(self):
        """å…¨ã‚µãƒ¼ãƒ“ã‚¹ä¸¦è¡Œå®Ÿè¡Œã®ãƒ†ã‚¹ãƒˆ"""
        runner = ServiceRunner()
        
        # å„ã‚µãƒ¼ãƒ“ã‚¹ã®collectãƒ¡ã‚½ãƒƒãƒ‰ã‚’ãƒ¢ãƒƒã‚¯
        for service in runner.services:
            service.collect = AsyncMock()
        
        await runner.run_all()
        
        # ã™ã¹ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒå‘¼ã°ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        for service in runner.services:
            service.collect.assert_called_once()
    
    async def test_concurrent_execution(self):
        """ä¸¦è¡Œå®Ÿè¡Œã®ç¢ºèª"""
        runner = ServiceRunner()
        
        call_times = []
        
        async def mock_collect(service_name):
            call_times.append((service_name, asyncio.get_event_loop().time()))
            await asyncio.sleep(0.1)  # 100ms ã®å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        
        # å„ã‚µãƒ¼ãƒ“ã‚¹ã®collectãƒ¡ã‚½ãƒƒãƒ‰ã‚’ãƒ¢ãƒƒã‚¯
        for service in runner.services:
            service.collect = lambda s=service.service_name: mock_collect(s)
        
        start_time = asyncio.get_event_loop().time()
        await runner.run_all()
        end_time = asyncio.get_event_loop().time()
        
        # ä¸¦è¡Œå®Ÿè¡Œãªã®ã§ã€å…¨ä½“ã®å®Ÿè¡Œæ™‚é–“ã¯å€‹ã€…ã®åˆè¨ˆã‚ˆã‚ŠçŸ­ã„ã¯ãš
        total_time = end_time - start_time
        assert total_time < 0.5  # 5ã‚µãƒ¼ãƒ“ã‚¹Ã—0.1ç§’ = 0.5ç§’ã‚ˆã‚ŠçŸ­ã„
        
        # ã™ã¹ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒã»ã¼åŒæ™‚ã«é–‹å§‹ã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        start_times = [t[1] for t in call_times]
        assert max(start_times) - min(start_times) < 0.05
```

## å®Œäº†æ¡ä»¶

1. éåŒæœŸHTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã“ã¨
2. ãƒ¬ãƒ¼ãƒˆåˆ¶é™æ©Ÿèƒ½ãŒå‹•ä½œã™ã‚‹ã“ã¨
3. æ—¢å­˜ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒéåŒæœŸå‡¦ç†ã«ç§»è¡Œã•ã‚Œã¦ã„ã‚‹ã“ã¨
4. ã‚µãƒ¼ãƒ“ã‚¹ãŒä¸¦è¡Œå®Ÿè¡Œã•ã‚Œã‚‹ã“ã¨
5. ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã™ã‚‹ã“ã¨
6. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã™ã‚‹ã“ã¨ï¼ˆå®Ÿè¡Œæ™‚é–“30%ä»¥ä¸ŠçŸ­ç¸®ï¼‰

## æ³¨æ„äº‹é …

1. æ—¢å­˜ã®åŒæœŸå‡¦ç†ã¨ã®äº’æ›æ€§ã‚’ä¿ã¤
2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’é©åˆ‡ã«è¡Œã†
3. ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å¿˜ã‚Œãªã„
4. ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ã‚’é¿ã‘ã‚‹
5. ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã«æ³¨æ„

## ä¾å­˜é–¢ä¿‚

- TASK-001ã®å®Œäº†ï¼ˆåŸºåº•ã‚¯ãƒ©ã‚¹ï¼‰
- TASK-002ã®å®Œäº†ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼‰
- httpx >= 0.24.0
- asyncio (Pythonæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª)

## æœŸé™

3æ—¥é–“