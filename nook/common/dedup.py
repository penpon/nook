"""ã‚¿ã‚¤ãƒˆãƒ«é‡è¤‡æ’é™¤ã®ãŸã‚ã®å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€‚"""

import re
import unicodedata


class TitleNormalizer:
    """
    è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ­£è¦åŒ–ã—ã¦é‡è¤‡åˆ¤å®šã‚’è¡Œã†ã‚¯ãƒ©ã‚¹ã€‚

    åŒä¸€ã‚µãƒ¼ãƒ“ã‚¹å†…ã§ç•°ãªã‚‹ã‚«ãƒ†ã‚´ãƒªã«å±ã—ã¦ã„ã¦ã‚‚ã€
    ã‚¿ã‚¤ãƒˆãƒ«ãŒå®Ÿè³ªçš„ã«åŒã˜ã§ã‚ã‚Œã°é‡è¤‡ã¨åˆ¤å®šã—ã¾ã™ã€‚

    æ­£è¦åŒ–æ‰‹é †:
    1. Unicodeæ­£è¦åŒ–ï¼ˆNFKCï¼‰ã§å…¨è§’/åŠè§’ã‚’çµ±ä¸€
    2. casefold()ã§å¤§æ–‡å­—å°æ–‡å­—ã‚’ç„¡è¦–
    3. ä½™åˆ†ãªç©ºç™½ã‚’åœ§ç¸®ãƒ»ãƒˆãƒªãƒ 
    4. è»½åº¦ã®è£…é£¾è¨˜å·ã‚’é™¤å»ï¼ˆã€ã€‘ã€[]ã€()ãªã©ï¼‰
    """

    # é™¤å»ã™ã‚‹è£…é£¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå…ˆé ­ãƒ»æœ«å°¾ã®æ‹¬å¼§ç³»ï¼‰
    DECORATION_PATTERNS = [
        r"^ã€[^ã€‘]*ã€‘",  # å…ˆé ­ã®ã€ã€‘
        r"^ã€Œ[^ã€]*ã€",  # å…ˆé ­ã®ã€Œã€
        r"^ã€[^ã€]*ã€",  # å…ˆé ­ã®ã€ã€
        r"ã€[^ã€‘]*ã€‘$",  # æœ«å°¾ã®ã€ã€‘
        r"ã€Œ[^ã€]*ã€$",  # æœ«å°¾ã®ã€Œã€
        r"ã€[^ã€]*ã€$",  # æœ«å°¾ã®ã€ã€
    ]

    @staticmethod
    def normalize(title: str) -> str:
        """
        ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ­£è¦åŒ–ã—ã¾ã™ã€‚

        Parameters
        ----------
        title : str
            æ­£è¦åŒ–ã™ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ã€‚

        Returns
        -------
        str
            æ­£è¦åŒ–ã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ã€‚
        """
        if not title:
            return ""

        # 1. Unicodeæ­£è¦åŒ–ï¼ˆNFKC: å…¨è§’/åŠè§’ã®çµ±ä¸€ï¼‰
        normalized = unicodedata.normalize("NFKC", title)

        # 2. å¤§æ–‡å­—å°æ–‡å­—ã®ç„¡è¦–ï¼ˆå¤šè¨€èªå¯¾å¿œï¼‰
        normalized = normalized.casefold()

        # 3. ä½™åˆ†ãªç©ºç™½ã®åœ§ç¸®ã¨ãƒˆãƒªãƒ 
        normalized = re.sub(r"\s+", " ", normalized).strip()

        # 4. è»½åº¦ã®è£…é£¾é™¤å»ï¼ˆå…ˆé ­ãƒ»æœ«å°¾ã®æ‹¬å¼§ç³»ï¼‰
        for pattern in TitleNormalizer.DECORATION_PATTERNS:
            normalized = re.sub(pattern, "", normalized).strip()

        # 5. è¨˜å·ã®æ­£è¦åŒ–ï¼ˆé€£ç¶šã™ã‚‹è¨˜å·ã‚’1ã¤ã«ï¼‰
        normalized = re.sub(r"[!ï¼]{2,}", "!", normalized)
        normalized = re.sub(r"[?ï¼Ÿ]{2,}", "?", normalized)
        normalized = re.sub(r"[~ï½]{2,}", "~", normalized)

        return normalized

    @staticmethod
    def are_duplicates(title1: str, title2: str) -> bool:
        """
        2ã¤ã®ã‚¿ã‚¤ãƒˆãƒ«ãŒé‡è¤‡ã—ã¦ã„ã‚‹ã‹åˆ¤å®šã—ã¾ã™ã€‚

        Parameters
        ----------
        title1 : str
            1ã¤ç›®ã®ã‚¿ã‚¤ãƒˆãƒ«ã€‚
        title2 : str
            2ã¤ç›®ã®ã‚¿ã‚¤ãƒˆãƒ«ã€‚

        Returns
        -------
        bool
            é‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã¯Trueã€ãã†ã§ãªã‘ã‚Œã°Falseã€‚
        """
        return TitleNormalizer.normalize(title1) == TitleNormalizer.normalize(title2)


class DedupTracker:
    """
    è¨˜äº‹ã®é‡è¤‡è¿½è·¡ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹ã€‚

    ã‚µãƒ¼ãƒ“ã‚¹å†…ã®ã‚«ãƒ†ã‚´ãƒªæ¨ªæ–­ã§ã€æ­£è¦åŒ–ã‚¿ã‚¤ãƒˆãƒ«ã«ã‚ˆã‚‹é‡è¤‡ã‚’è¿½è·¡ã—ã¾ã™ã€‚
    """

    def __init__(self):
        """DedupTrackerã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"""
        self.seen_normalized_titles = set()
        self.title_mapping = {}  # æ­£è¦åŒ–ã‚¿ã‚¤ãƒˆãƒ« -> å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆãƒ­ã‚°ç”¨ï¼‰

    def is_duplicate(self, title: str) -> tuple[bool, str]:
        """
        ã‚¿ã‚¤ãƒˆãƒ«ãŒé‡è¤‡ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚

        Parameters
        ----------
        title : str
            ç¢ºèªã™ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ã€‚

        Returns
        -------
        tuple[bool, str]
            (é‡è¤‡ã—ã¦ã„ã‚‹ã‹, æ­£è¦åŒ–ã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«)
        """
        normalized = TitleNormalizer.normalize(title)
        is_dup = normalized in self.seen_normalized_titles
        return is_dup, normalized

    def add(self, title: str) -> str:
        """
        ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿½è·¡å¯¾è±¡ã«è¿½åŠ ã—ã¾ã™ã€‚

        Parameters
        ----------
        title : str
            è¿½åŠ ã™ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ã€‚

        Returns
        -------
        str
            æ­£è¦åŒ–ã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ã€‚
        """
        normalized = TitleNormalizer.normalize(title)
        self.seen_normalized_titles.add(normalized)
        if normalized not in self.title_mapping:
            self.title_mapping[normalized] = title
        return normalized

    def get_original_title(self, normalized_title: str) -> str | None:
        """
        æ­£è¦åŒ–ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ã—ã¾ã™ï¼ˆãƒ­ã‚°ç”¨ï¼‰ã€‚

        Parameters
        ----------
        normalized_title : str
            æ­£è¦åŒ–ã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ã€‚

        Returns
        -------
        str or None
            å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ã€‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneã€‚
        """
        return self.title_mapping.get(normalized_title)

    def count(self) -> int:
        """
        è¿½è·¡ä¸­ã®é‡è¤‡æ’é™¤æ¸ˆã¿ã‚¿ã‚¤ãƒˆãƒ«æ•°ã‚’è¿”ã—ã¾ã™ã€‚

        Returns
        -------
        int
            è¿½è·¡ä¸­ã®ã‚¿ã‚¤ãƒˆãƒ«æ•°ã€‚
        """
        return len(self.seen_normalized_titles)


async def load_existing_titles_from_storage(
    storage,
    target_dates: set,
    logger=None,
) -> DedupTracker:
    """
    æŒ‡å®šæœŸé–“ã®æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦é‡è¤‡ãƒã‚§ãƒƒã‚«ãƒ¼ã‚’è¿”ã™ã€‚

    æ—¢å­˜ã®JSON/Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’èª­ã¿è¾¼ã¿ã€
    DedupTrackerã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€
    æ—¢ã«è¦ç´„æ¸ˆã¿ã®è¨˜äº‹ã‚’å†åº¦å‡¦ç†ã™ã‚‹ã“ã¨ã‚’é˜²ãã¾ã™ã€‚

    Parameters
    ----------
    storage : LocalStorage
        ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨ã®LocalStorageã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚
    target_dates : set[date]
        ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®æ—¥ä»˜ã®ã‚»ãƒƒãƒˆã€‚
    logger : logging.Logger, optional
        ãƒ­ã‚°å‡ºåŠ›ç”¨ã®ãƒ­ã‚¬ãƒ¼ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ã€‚

    Returns
    -------
    DedupTracker
        æ—¢å­˜ã‚¿ã‚¤ãƒˆãƒ«ãŒç™»éŒ²ã•ã‚ŒãŸDedupTrackerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚

    Examples
    --------
    >>> from datetime import date
    >>> target_dates = {date(2025, 11, 1), date(2025, 11, 2)}
    >>> tracker = await load_existing_titles_from_storage(storage, target_dates)
    >>> is_dup, _ = tracker.is_duplicate("æ—¢å­˜è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«")
    >>> print(is_dup)
    True
    """
    import json
    from datetime import time, datetime

    tracker = DedupTracker()

    for target_date in sorted(target_dates):
        date_str = target_date.strftime("%Y-%m-%d")

        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¢å­˜è¨˜äº‹ã‚’èª­ã¿è¾¼ã¿
        try:
            json_content = await storage.load(f"{date_str}.json")
            if json_content:
                articles = json.loads(json_content)
                for article in articles:
                    title = article.get("title", "")
                    if title:
                        tracker.add(title)
                if logger:
                    logger.debug(
                        f"ğŸ“‚ æ—¢å­˜è¨˜äº‹èª­ã¿è¾¼ã¿: {date_str}.json ({len(articles)}ä»¶)"
                    )
        except FileNotFoundError:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if logger:
                logger.debug(f"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«æœªæ¤œå‡º: {date_str}.json")
        except json.JSONDecodeError as e:
            if logger:
                logger.warning(f"âš ï¸ JSONè§£æã‚¨ãƒ©ãƒ¼: {date_str}.json - {e}")
        except Exception as e:
            if logger:
                logger.debug(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {date_str}.json - {e}")

        # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚‚èª­ã¿è¾¼ã¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        try:
            markdown_content = storage.load_markdown(
                "", datetime.combine(target_date, time.min)
            )
            if markdown_content:
                # Markdownã‹ã‚‰è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡ºï¼ˆ### [ã‚¿ã‚¤ãƒˆãƒ«](URL) å½¢å¼ï¼‰
                import re

                for match in re.finditer(
                    r"^### \[(.+?)\]", markdown_content, re.MULTILINE
                ):
                    title = match.group(1)
                    tracker.add(title)
                if logger:
                    logger.debug(f"ğŸ“‚ æ—¢å­˜è¨˜äº‹èª­ã¿è¾¼ã¿: {date_str}.md")
        except Exception as e:
            if logger:
                logger.debug(f"âš ï¸ Markdownèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {date_str}.md - {e}")

    return tracker
