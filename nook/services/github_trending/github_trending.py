"""GitHubã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã‚’åé›†ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã€‚"""

from dataclasses import dataclass
from datetime import date, datetime, time, timezone
from pathlib import Path
from textwrap import dedent
import re

from typing import Any

import tomli
from bs4 import BeautifulSoup

from nook.common.base_service import BaseService
from nook.common.decorators import handle_errors
from nook.common.exceptions import APIException
from nook.common.dedup import DedupTracker
from nook.common.daily_snapshot import group_records_by_date, store_daily_snapshots
from nook.common.date_utils import target_dates_set


@dataclass
class Repository:
    """
    GitHubãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã€‚

    Parameters
    ----------
    name : str
        ãƒªãƒã‚¸ãƒˆãƒªåã€‚
    description : str | None
        èª¬æ˜ã€‚
    link : str
        ãƒªãƒã‚¸ãƒˆãƒªã¸ã®ãƒªãƒ³ã‚¯ã€‚
    stars : int
        ã‚¹ã‚¿ãƒ¼æ•°ã€‚
    """

    name: str
    description: str | None
    link: str
    stars: int


class GithubTrending(BaseService):
    """
    GitHubã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã‚’åé›†ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚

    Parameters
    ----------
    storage_dir : str, default="data"
        ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã€‚
    """

    def __init__(self, storage_dir: str = "data"):
        """
        GithubTrendingã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚

        Parameters
        ----------
        storage_dir : str, default="data"
            ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã€‚
        """
        super().__init__("github_trending")
        self.base_url = "https://github.com/trending"
        self.http_client = None  # setup_http_clientã§åˆæœŸåŒ–

        # è¨€èªã®è¨­å®šã‚’èª­ã¿è¾¼ã‚€
        script_dir = Path(__file__).parent
        with open(script_dir / "languages.toml", "rb") as f:
            self.languages_config = tomli.load(f)

    async def collect(
        self,
        limit: int = 5,
        *,
        target_dates: set[date] | None = None,
    ) -> list[tuple[str, str]]:
        """
        GitHubã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã‚’åé›†ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚

        Parameters
        ----------
        limit : int, default=5
            å„è¨€èªã‹ã‚‰å–å¾—ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªæ•°ã€‚

        Returns
        -------
        list[tuple[str, str]]
            ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ [(json_path, md_path), ...]
        """
        # HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã‚’ç¢ºèª
        if self.http_client is None:
            await self.setup_http_client()

        effective_target_dates = target_dates or target_dates_set(1)

        # å¯¾è±¡æ—¥ä»˜ã®ãƒ­ã‚°å‡ºåŠ›
        date_str = max(effective_target_dates).strftime("%Y-%m-%d")
        self.logger.info(f"ğŸ“° [{date_str}] ã®è¨˜äº‹ã‚’å‡¦ç†ä¸­...")

        dedup_tracker = self._load_existing_repositories()
        all_repositories = []

        # è¨€èªæŒ‡å®šãªã—ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—ï¼ˆæ–°è¦è¿½åŠ ï¼‰
        repositories = await self._retrieve_repositories("any", limit, dedup_tracker)
        all_repositories.append(("all", repositories))
        await self.rate_limit()  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’éµå®ˆ

        # ä¸€èˆ¬çš„ãªè¨€èªã®ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—
        for language in self.languages_config["general"]:
            repositories = await self._retrieve_repositories(
                language, limit, dedup_tracker
            )
            all_repositories.append((language, repositories))
            await self.rate_limit()  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’éµå®ˆ

        # ç‰¹å®šã®è¨€èªã®ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—ï¼ˆlimitã¨åŒã˜æ•°ã«å¤‰æ›´ï¼‰
        for language in self.languages_config["specific"]:
            # limit // 2 â†’ limit
            repositories = await self._retrieve_repositories(
                language, limit, dedup_tracker
            )
            all_repositories.append((language, repositories))
            await self.rate_limit()  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’éµå®ˆ

        # ç¿»è¨³å‡¦ç†
        all_repositories = await self._translate_repositories(all_repositories)

        # ä¿å­˜
        saved_files = await self._store_summaries(
            all_repositories, limit, effective_target_dates
        )

        # å‡¦ç†å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        if saved_files:
            self.logger.info(f"\nğŸ’¾ {len(saved_files)}æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜å®Œäº†")
            for json_path, md_path in saved_files:
                self.logger.info(f"   ğŸ’¾ ä¿å­˜å®Œäº†: {json_path}, {md_path}")
        else:
            self.logger.info("\nä¿å­˜ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“")

        return saved_files

    @handle_errors(retries=3)
    async def _retrieve_repositories(
        self, language: str, limit: int, dedup_tracker: DedupTracker
    ) -> list[Repository]:
        """
        ç‰¹å®šã®è¨€èªã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—ã—ã¾ã™ã€‚

        Parameters
        ----------
        language : str
            è¨€èªåï¼ˆç©ºæ–‡å­—åˆ—ã®å ´åˆã¯ã™ã¹ã¦ã®è¨€èªï¼‰ã€‚
        limit : int
            å–å¾—ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªæ•°ã€‚

        Returns
        -------
        List[Repository]
            å–å¾—ã—ãŸãƒªãƒã‚¸ãƒˆãƒªã®ãƒªã‚¹ãƒˆã€‚
        """
        url = self.base_url
        if language:
            url += f"/{language}"

        try:
            response = await self.http_client.get(url)
            soup = BeautifulSoup(response.text, "html.parser")

            repositories = []
            repo_elements = soup.select("article.Box-row")

            for repo_element in repo_elements:
                # ãƒªãƒã‚¸ãƒˆãƒªåã‚’å–å¾—
                name_element = repo_element.select_one("h2 a")
                if not name_element:
                    continue

                name = name_element.text.strip().replace("\n", "").replace(" ", "")
                link = f"https://github.com{name_element['href']}"

                is_dup, normalized = dedup_tracker.is_duplicate(name)
                if is_dup:
                    original = dedup_tracker.get_original_title(normalized) or name
                    self.logger.info(
                        "é‡è¤‡ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¹ã‚­ãƒƒãƒ—: '%s' (åˆå‡º: '%s')",
                        name,
                        original,
                    )
                    continue

                # èª¬æ˜ã‚’å–å¾—
                description_element = repo_element.select_one("p")
                description = (
                    description_element.text.strip() if description_element else None
                )

                # ã‚¹ã‚¿ãƒ¼æ•°ã‚’å–å¾—
                stars_element = repo_element.select_one("a.Link--muted")
                stars_text = stars_element.text.strip() if stars_element else "0"
                stars = (
                    int(stars_text.replace(",", ""))
                    if stars_text.replace(",", "").isdigit()
                    else 0
                )

                repository = Repository(
                    name=name, description=description, link=link, stars=stars
                )

                repositories.append(repository)
                dedup_tracker.add(name)

                if len(repositories) >= limit:
                    break

            return repositories

        except Exception as e:
            self.logger.error(
                f"Error retrieving repositories for language {language}: {str(e)}"
            )
            raise APIException(f"Failed to retrieve repositories for {language}") from e

    def _load_existing_repositories(self) -> DedupTracker:
        tracker = DedupTracker()
        try:
            today = datetime.now().strftime("%Y-%m-%d")
            file_path = Path(self.storage.base_dir) / f"{today}.md"
            if file_path.exists():
                content = file_path.read_text(encoding="utf-8")
                for match in re.finditer(r"^### \[(.+?)\]", content, re.MULTILINE):
                    tracker.add(match.group(1))
        except Exception as exc:
            self.logger.debug(f"æ—¢å­˜ãƒªãƒã‚¸ãƒˆãƒªã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
        return tracker

    async def _translate_repositories(
        self, repositories_by_language: list[tuple[str, list[Repository]]]
    ) -> list[tuple[str, list[Repository]]]:
        """
        ãƒªãƒã‚¸ãƒˆãƒªã®èª¬æ˜ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¾ã™ã€‚

        Parameters
        ----------
        repositories_by_language : List[tuple[str, List[Repository]]]
            è¨€èªã”ã¨ã®ãƒªãƒã‚¸ãƒˆãƒªãƒªã‚¹ãƒˆã€‚

        Returns
        -------
        List[tuple[str, List[Repository]]]
            ç¿»è¨³ã•ã‚ŒãŸãƒªãƒã‚¸ãƒˆãƒªãƒªã‚¹ãƒˆã€‚
        """
        try:
            for language, repositories in repositories_by_language:
                for repo in repositories:
                    if repo.description:
                        prompt = dedent(
                            f"""
                            ä»¥ä¸‹ã®GitHubãƒªãƒã‚¸ãƒˆãƒªã®èª¬æ˜æ–‡ã‚’æ—¥æœ¬èªã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚
                            åˆ¶ç´„:
                            - æ¦‚è¦ã¯åˆè¨ˆã§300æ–‡å­—ä»¥å†…ã‚’ç›®å®‰ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã€‚
                            - ç®‡æ¡æ›¸ãã‚’è¿½åŠ ã—ã€3é …ç›®ã¨ã™ã‚‹ã“ã¨ã€‚
                            - æ–°ã—ã„æƒ…å ±ã‚’æ¨æ¸¬ã›ãšã€åŸæ–‡ã®å†…å®¹ã«åŸºã¥ã„ã¦èª¬æ˜ã™ã‚‹ã“ã¨ã€‚
                            - å‡ºåŠ›å½¢å¼ï¼š
                              æ¦‚è¦: <æ¦‚è¦>
                              ä¸»ãªãƒã‚¤ãƒ³ãƒˆ:
                              - <ãƒã‚¤ãƒ³ãƒˆ1>
                              - <ãƒã‚¤ãƒ³ãƒˆ2>

                            ãƒªãƒã‚¸ãƒˆãƒªå: {repo.name}
                            åŸæ–‡èª¬æ˜: {repo.description}
                            """
                        )
                        try:
                            repo.description = await self.gpt_client.generate_async(
                                prompt=prompt,
                                temperature=0.3,
                                max_tokens=300,
                            )
                            if repo.description:
                                repo.description = repo.description.strip()
                            await self.rate_limit()  # APIå‘¼ã³å‡ºã—å¾Œã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™
                        except Exception as e:
                            self.logger.error(
                                f"Error translating description for {repo.name}: {str(e)}"
                            )

        except Exception as e:
            self.logger.error(f"Error in translation process: {str(e)}")

        return repositories_by_language

    async def _store_summaries(
        self,
        repositories_by_language: list[tuple[str, list[Repository]]],
        limit_per_language: int | None,
        target_dates: set[date],
    ) -> list[tuple[str, str]]:
        """
        ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’ä¿å­˜ã—ã¾ã™ã€‚

        Parameters
        ----------
        repositories_by_language : List[tuple[str, List[Repository]]]
            è¨€èªã”ã¨ã®ãƒªãƒã‚¸ãƒˆãƒªãƒªã‚¹ãƒˆã€‚
        limit_per_language : int | None
            å„è¨€èªã®æœ€å¤§ä»¶æ•°ã€‚None ã®å ´åˆã¯å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ä»¶æ•°ã‚’åˆ©ç”¨ã€‚

        Returns
        -------
        list[tuple[str, str]]
            ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ [(json_path, md_path), ...]
        """
        if not repositories_by_language:
            self.logger.info("ä¿å­˜ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“")
            return []

        default_date = max(target_dates) if target_dates else datetime.now().date()
        records = self._serialize_repositories(repositories_by_language, default_date)
        records_by_date = group_records_by_date(records, default_date=default_date)

        saved_files = await store_daily_snapshots(
            records_by_date,
            load_existing=self._load_existing_repositories_by_date,
            save_json=self.save_json,
            save_markdown=self.save_markdown,
            render_markdown=self._render_markdown,
            key=lambda item: item.get("name", ""),
            sort_key=self._repository_sort_key,
            limit=None,
            logger=self.logger,
        )

        return saved_files

    def _serialize_repositories(
        self,
        repositories_by_language: list[tuple[str, list[Repository]]],
        default_date: date,
    ) -> list[dict[str, Any]]:
        serialized: list[dict[str, Any]] = []
        base_dt = datetime.combine(default_date, time.min, tzinfo=timezone.utc)
        now_iso = base_dt.isoformat()
        for language, repositories in repositories_by_language:
            for repo in repositories:
                serialized.append(
                    {
                        "language": language,
                        "name": repo.name,
                        "description": repo.description,
                        "link": repo.link,
                        "stars": repo.stars,
                        "published_at": now_iso,
                    }
                )
        return serialized

    async def _load_existing_repositories_by_date(
        self, target_date: datetime
    ) -> list[dict[str, Any]]:
        date_str = target_date.strftime("%Y-%m-%d")
        filename_json = f"{date_str}.json"
        existing_json = await self.load_json(filename_json)
        if existing_json:
            if isinstance(existing_json, dict):
                flattened: list[dict[str, Any]] = []
                for language, repos in existing_json.items():
                    for repo in repos:
                        flattened.append({"language": language, **repo})
                return flattened
            return existing_json

        markdown_content = await self.storage.load(f"{date_str}.md")
        if not markdown_content:
            return []

        return self._parse_markdown(markdown_content)

    def _repository_sort_key(self, item: dict[str, Any]) -> tuple[int, datetime]:
        stars = int(item.get("stars", 0) or 0)
        published_raw = item.get("published_at")
        if published_raw:
            try:
                published = datetime.fromisoformat(published_raw)
            except ValueError:
                published = datetime.min.replace(tzinfo=timezone.utc)
        else:
            published = datetime.min.replace(tzinfo=timezone.utc)
        return (stars, published)

    def _render_markdown(self, records: list[dict[str, Any]], today: datetime) -> str:
        content = f"# GitHub ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªãƒã‚¸ãƒˆãƒª ({today.strftime('%Y-%m-%d')})\n\n"

        grouped: dict[str, list[dict[str, Any]]] = {}
        for record in records:
            language = record.get("language", "all")
            grouped.setdefault(language, []).append(record)

        for language, repositories in grouped.items():
            if not repositories:
                continue

            language_display = language if language != "all" else "ã™ã¹ã¦ã®è¨€èª"
            content += f"## {language_display.capitalize()}\n\n"

            for repo in repositories:
                content += f"### [{repo['name']}]({repo.get('link')})\n\n"

                description = repo.get("description")
                if description:
                    content += f"{description}\n\n"

                content += f"â­ ã‚¹ã‚¿ãƒ¼æ•°: {repo.get('stars', 0)}\n\n"
                content += "---\n\n"

        return content

    def _parse_markdown(self, content: str) -> list[dict[str, Any]]:
        records: list[dict[str, Any]] = []
        language_pattern = re.compile(r"^##\s+(.+)$", re.MULTILINE)
        repo_pattern = re.compile(
            r"### \[(?P<name>.+?)\]\((?P<link>[^\)]+)\)\n\n"
            r"(?P<description>.*?)(?:\n\n)?â­ ã‚¹ã‚¿ãƒ¼æ•°: (?P<stars>[0-9,]+)",
            re.DOTALL,
        )

        sections = list(language_pattern.finditer(content))
        for idx, match in enumerate(sections):
            start = match.end()
            end = sections[idx + 1].start() if idx + 1 < len(sections) else len(content)
            section_content = content[start:end]

            language_header = match.group(1).strip()
            language_key = (
                "all"
                if language_header.lower().startswith("ã™ã¹ã¦")
                else language_header.lower()
            )

            for repo_match in repo_pattern.finditer(section_content):
                name = repo_match.group("name").strip()
                link = repo_match.group("link").strip()
                description = repo_match.group("description").strip()
                stars_text = repo_match.group("stars")
                stars = int(stars_text.replace(",", "")) if stars_text else 0

                records.append(
                    {
                        "language": language_key,
                        "name": name,
                        "link": link,
                        "description": description,
                        "stars": stars,
                    }
                )

        return records
